# Machine Learning Course

Stuff from my machine learning course

## Course Description
The course introduces the basic theory and algorithms of machine learning. It covers both supervised and unsupervised learning, theoretical foundations of generalization, and practical algorithms widely used in the field.  

## Topics Covered

### Supervised Learning
- Classification
- Regression
- Algorithms:
  - K-Nearest Neighbors (KNN)
  - Perceptron
  - Logistic Regression
  - Linear Regression
  - Decision Trees & Random Forests
  - Neural Networks (introduction to Deep Learning)

### Unsupervised Learning
- Clustering
  - k-means
  - k-means++
- Dimensionality Reduction
  - Principal Component Analysis (PCA)

### Theoretical Foundations
- Concentration of measure inequalities:
  - Markov's inequality
  - Chebyshev's inequality
  - Hoeffding's inequality
- Generalization in classification:
  - Validation and cross-validation
  - Generalization bounds (single hypothesis, finite class, infinite class via Occam’s razor)

### Regularization
- Regularization terms and their effects
- Feature transformations
- Classification/regression in transformed feature spaces

### Assumptions, Bias, and Pitfalls
- Overfitting
  - Internal (within algorithms, due to complex hypothesis spaces)
  - External (across algorithms, due to excessive use on datasets)
- The i.i.d. assumption:
  - Importance and consequences of violation
  - Sampling bias as a special case
  - Failure of generalization guarantees
  - Biases in training data → biased predictions
- Correlation vs. Causality:
  - Only statistical dependencies are studied
  - Causal inference is **not** covered in this course

---

## Notes
- All examples and projects are for **educational purposes**.  
- The course focuses on **statistical learning theory** and **practical algorithms**, but not causal inference.  

